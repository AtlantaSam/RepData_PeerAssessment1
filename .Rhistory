View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
cran %>%
select(ip_id,country,package,size) %>%
print(cran)
cran %>%
select(ip_id,country,package,size) %>%
print(cran)
submit()
bye()
library(swirl)
R.version(0)
R.version()
R.Version()
R.Version
R.Version()
swirl()
library("swirl")
swirl()
reset()
info()
main()
pack_sum
top_counts <- filter(pack_sum, count>679)
View(top_counts)
arrange(top_counts, desc(count))
arrange(top_counts, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
cran %>%
select(ip_id,country,package,size) %>%
print
submit()
info()
skip()
submit()
mutate(size_mb = size / 2^20)
mutate(cran, size_mb = size / 2^20)
submit()
nxt()
skip()
submit()
filter(size_mb<=0.5)
filter(size_mb <= 0.5)
skip()
submit()
skip()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
install.packages(ggplot2)
install.packages(ggplot)
install.packages("ggplot2")
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("ggplot2")
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
title: "Reproducible Research"
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("jpeg", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("knitr")
setwd("~/Dropbox/EDX/Sabremetrics/R files")
setwd("~/Dropbox/EDX/Sabremetrics/data")
require("lattice")
setwd("~/Dropbox/EDX/Sabremetrics/data")
win_estimators <- read.csv("winest.csv")
View(win_estimators)
View(win_estimators)
# Summary stats
summary(win_estimators)
mean(win_estimators$WPct)
sd(win_estimators$WPct)
estimators <- win_estimators[c("RPG", "RAPG", "WPct","Cook",  "Soolman",  "Kross", "Smyth", "JamesPythag1", "JamesPythag2")]
View(estimators)
View(estimators)
splom(estimators, xlab="Win Estimators")
View(win_estimators)
View(win_estimators)
View(estimators)
View(estimators)
View(win_estimators)
plot(yearID,rpg)
win_estimators <- read.csv("winest.csv")
plot(yearID,rpg)
plot(RPG,yearID)
plot(win_estimators$RPG,win_estimators$yearID)
plot(win_estimators$year_id,win_estimators$RPG)
plot(win_estimators$year_id,win_estimators$RPG)
plot(win_estimators$yearID,win_estimators$RPG)
summary(win_estimators)
mean(win_estimators$WPct)
sd(win_estimators$WPct)
table(win_estimators$yearID)
wpct_95th_pct = quantile(estimators$WPct, .95)
top_winners = estimators[estimators$WPct >= wpct_95th_pct, ]
summary(top_winners)
mean(top_winners$WPct)
splom(top_winners, xlab="Top 5th Percentile WPct")
View(top_winners)
estimators_1960s = win_estimators[win_estimators$yearID < 1970 & win_estimators$yearID >= 1960, ]
summary(estimators_1960s)
cor(estimators_1960s$WPct, estimators_1960s$JamesPythag1)
cor(estimators_1960s$WPct, estimators_1960s$JamesPythag2)
cor(estimators_1960s$WPct, estimators_1960s$Cook)
cor(estimators_1960s$WPct, estimators_1960s$Soolman)
cor(estimators_1960s$WPct, estimators_1960s$Kross)
cor(estimators_1960s$WPct, estimators_1960s$Smyth)
estimators_2000s = win_estimators[win_estimators$yearID < 2010 & win_estimators$yearID >= 2000, ]
cor(estimators_2000s$WPct, estimators_2000s$JamesPythag1)
cor(estimators_2000s$WPct, estimators_2000s$Cook)
cor(estimators_2000s$WPct, estimators_2000s$Soolman)
# Import data
year_team <- read.csv(file.choose())
View(year_team)
year_team$AVG <- with(year_team, (H/(AB)))
year_team$OBP <- with(year_team, ((H+BB+HBP)/(AB+BB+HBP+SF)))
year_team$SLG <- with(year_team, ((H+X2B+2*X3B+3*HR)/(AB)))
year_team$OPS <- with(year_team, OBP + SLG)
View(year_team)
year_team <- read.csv(file.choose())
setwd("~/Dropbox/EDX/Sabremetrics/data")
year_team <- read.csv(file.choose())
corr_plot <- function(v1, v2, df) {
plot(df[[v1]], df[[v2]], xlab=v1, ylab=v2) # Draw scatter Plot
linfit <- lm(df[[v2]]~df[[v1]]) # Calculate best-fit line
abline(linfit) # Draw best-fit line
# Add R^2 value in legend
legend("topleft", legend = paste("R^2:", signif(summary(linfit)$r.squared, 4)))
}
# Add 1B for calculation simplicity
year_team$X1B <- with(year_team, H-X2B-X3B-HR)
# First we'll only use different types of hits
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
lin_basic_weights
year_team$linRBasic <- predict(lin_basic_weights)
View(year_team)
View(year_team)
lin_more_weights <- lm(R ~ X1B + X2B + X3B + HR + I(BB + HBP) + SB, data=year_team)
year_team$linRMore <- predict(lin_more_weights)
year_team$linRBasic <- predict(lin_basic_weights)
linRBasic
year_team$linRBasic <- predict(lin_basic_weights)
year_team$linRBasic
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
lin_basic_weights
#running correlation plots
corr_plot('HR', 'HR', year_team)
corr_plot('HR', 'HBP', year_team)
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
corr_plot('linRBasic', 'R', year_team)
corr_plot('linRMore', 'R', year_team)
corr_plot('HR', 'HR', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('HR', 'HR', year_team)
corr_plot('HR', 'HBP', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('linRMore', 'R', year_team)
# Calculate AVG, SLG, OPS; then insert into data frame
year_team$AVG <- with(year_team, (H/(AB)))
year_team$OBP <- with(year_team, ((H+BB+HBP)/(AB+BB+HBP+SF)))
year_team$SLG <- with(year_team, ((H+X2B+2*X3B+3*HR)/(AB)))
year_team$OPS <- with(year_team, OBP + SLG)
# Correlation Plot Function
# Draws a scatter plot of 2 variables from a dataframe
# displaying a best-fit line and R^2 value in the legend
corr_plot <- function(v1, v2, df) {
plot(df[[v1]], df[[v2]], xlab=v1, ylab=v2) # Draw scatter Plot
linfit <- lm(df[[v2]]~df[[v1]]) # Calculate best-fit line
abline(linfit) # Draw best-fit line
# Add R^2 value in legend
legend("topleft", legend = paste("R^2:", signif(summary(linfit)$r.squared, 4)))
}
# Add 1B for calculation simplicity
year_team$X1B <- with(year_team, H-X2B-X3B-HR)
# First we'll only use different types of hits
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 1)
year_team$linRBasic <- predict(lin_basic_weights)
# Now let's add in BB, HBP, and SB to improve the regression's accuracy.
lin_more_weights <- lm(R ~ X1B + X2B + X3B + HR + I(BB + HBP) + SB, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 2)
year_team$linRMore <- predict(lin_more_weights)
#running correlation plots
corr_plot('HR', 'HR', year_team)
corr_plot('HR', 'HBP', year_team)
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
corr_plot('linRBasic', 'R', year_team)
corr_plot('linRMore', 'R', year_team)
corr_plot('SF', 'R', year_team)
orr_plot('HR', 'HBP', year_team)
corr_plot('HR', 'HR', year_team)
corr_plot('HR', 'HBP', year_team)
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
corr_plot('linRBasic', 'R', year_team)
corr_plot('linRMore', 'R', year_team)
# Calculate AVG, SLG, OPS; then insert into data frame
year_team$AVG <- with(year_team, (H/(AB)))
year_team$OBP <- with(year_team, ((H+BB+HBP)/(AB+BB+HBP)))
year_team$SLG <- with(year_team, ((H+X2B+2*X3B+3*HR)/(AB)))
year_team$OPS <- with(year_team, OBP + SLG)
# Correlation Plot Function
# Draws a scatter plot of 2 variables from a dataframe
# displaying a best-fit line and R^2 value in the legend
corr_plot <- function(v1, v2, df) {
plot(df[[v1]], df[[v2]], xlab=v1, ylab=v2) # Draw scatter Plot
linfit <- lm(df[[v2]]~df[[v1]]) # Calculate best-fit line
abline(linfit) # Draw best-fit line
# Add R^2 value in legend
legend("topleft", legend = paste("R^2:", signif(summary(linfit)$r.squared, 4)))
}
# Add 1B for calculation simplicity
year_team$X1B <- with(year_team, H-X2B-X3B-HR)
# First we'll only use different types of hits
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 1)
year_team$linRBasic <- predict(lin_basic_weights)
# Now let's add in BB, HBP, and SB to improve the regression's accuracy.
lin_more_weights <- lm(R ~ X1B + X2B + X3B + HR + I(BB + HBP) + SB, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 2)
year_team$linRMore <- predict(lin_more_weights)
#running correlation plots
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
year_team$AVG <- with(year_team, (H/(AB)))
year_team$OBP <- with(year_team, ((H+BB+HBP)/(AB+BB+HBP+SF)))
year_team$SLG <- with(year_team, ((H+X2B+2*X3B+3*HR)/(AB)))
year_team$OPS <- with(year_team, OBP + SLG)
# Correlation Plot Function
# Draws a scatter plot of 2 variables from a dataframe
# displaying a best-fit line and R^2 value in the legend
corr_plot <- function(v1, v2, df) {
plot(df[[v1]], df[[v2]], xlab=v1, ylab=v2) # Draw scatter Plot
linfit <- lm(df[[v2]]~df[[v1]]) # Calculate best-fit line
abline(linfit) # Draw best-fit line
# Add R^2 value in legend
legend("topleft", legend = paste("R^2:", signif(summary(linfit)$r.squared, 4)))
}
# Add 1B for calculation simplicity
year_team$X1B <- with(year_team, H-X2B-X3B-HR)
# First we'll only use different types of hits
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 1)
year_team$linRBasic <- predict(lin_basic_weights)
# Now let's add in BB, HBP, and SB to improve the regression's accuracy.
lin_more_weights <- lm(R ~ X1B + X2B + X3B + HR + I(BB + HBP) + SB, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 2)
year_team$linRMore <- predict(lin_more_weights)
#running correlation plots
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
corr_plot('linRBasic', 'R', year_team)
corr_plot('linRMore', 'R', year_team)
library("class", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:class", unload=TRUE)
require("lattice")
win_estimators <- read.csv("winest.csv")
View(win_estimators)
View(win_estimators)
# Scatter Plot
plot(win_estimators$yearID,win_estimators$RPG)
# Summary Stats
summary(win_estimators)
mean(win_estimators$WPct)
tony <- mean(win_estimators$WPct)
tony
t2 <- tony/2
t2
table(win_estimators$yearID)
estimators <- win_estimators[c("RPG", "RAPG", "WPct","Cook",  "Soolman",  "Kross", "Smyth", "JamesPythag1", "JamesPythag2")]
splom(estimators, xlab="Win Estimators")
wpct_95th_pct = quantile(estimators$WPct, .95)
top_winners = estimators[estimators$WPct >= wpct_95th_pct, ]
summary(top_winners)
mean(top_winners$WPct)
splom(top_winners, xlab="Top 5th Percentile WPct")
# Now for worst teams
wpct_5th_pct = quantile(estimators$WPct, .05)
worst_winners = estimators[estimators$WPct <= wpct_5th_pct, ]
summary(worst_winners)
mean(worst_winners$WPct)
splom(worst_winners, xlab="Bottom 5th Percentile WPct")
# Analysis by decades
estimators_1960s = win_estimators[win_estimators$yearID < 1970 & win_estimators$yearID >= 1960, ]
summary(estimators_1960s)
cor(estimators_1960s$WPct, estimators_1960s$JamesPythag1)
cor(estimators_1960s$WPct, estimators_1960s$JamesPythag2)
cor(estimators_1960s$WPct, estimators_1960s$Cook)
cor(estimators_1960s$WPct, estimators_1960s$Soolman)
cor(estimators_1960s$WPct, estimators_1960s$Kross)
cor(estimators_1960s$WPct, estimators_1960s$Smyth)
estimators_2000s = win_estimators[win_estimators$yearID < 2010 & win_estimators$yearID >= 2000, ]
cor(estimators_2000s$WPct, estimators_2000s$JamesPythag1)
cor(estimators_2000s$WPct, estimators_2000s$Cook)
cor(estimators_2000s$WPct, estimators_2000s$Soolman)
# Import data
# data: team_stats
setwd("~/Dropbox/EDX/Sabremetrics/data")
year_team <- read.csv(file.choose())
View(year_team)
# Import data
# data: team_stats
setwd("~/Dropbox/EDX/Sabremetrics/data")
year_team <- read.csv(file.choose())
# Calculate AVG, SLG, OPS; then insert into data frame
year_team$AVG <- with(year_team, (H/(AB)))
year_team$OBP <- with(year_team, ((H+BB+HBP)/(AB+BB+HBP+SF)))
year_team$SLG <- with(year_team, ((H+X2B+2*X3B+3*HR)/(AB)))
year_team$OPS <- with(year_team, OBP + SLG)
# Correlation Plot Function
# Draws a scatter plot of 2 variables from a dataframe
# displaying a best-fit line and R^2 value in the legend
corr_plot <- function(v1, v2, df) {
plot(df[[v1]], df[[v2]], xlab=v1, ylab=v2) # Draw scatter Plot
linfit <- lm(df[[v2]]~df[[v1]]) # Calculate best-fit line
abline(linfit) # Draw best-fit line
# Add R^2 value in legend
legend("topleft", legend = paste("R^2:", signif(summary(linfit)$r.squared, 4)))
}
# Add 1B for calculation simplicity
year_team$X1B <- with(year_team, H-X2B-X3B-HR)
# First we'll only use different types of hits
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 1)
year_team$linRBasic <- predict(lin_basic_weights)
# Now let's add in BB, HBP, and SB to improve the regression's accuracy.
lin_more_weights <- lm(R ~ X1B + X2B + X3B + HR + I(BB + HBP) + SB, data=year_team)
lin_basic_weights
# Apply model's coefficients to predict past runs (version 2)
year_team$linRMore <- predict(lin_more_weights)
#running correlation plots
corr_plot('SF', 'R', year_team)
corr_plot('AVG', 'R', year_team)
corr_plot('SLG', 'R', year_team)
corr_plot('OBP', 'R', year_team)
corr_plot('OPS', 'R', year_team)
corr_plot('linRBasic', 'R', year_team)
corr_plot('linRMore', 'R', year_team)
View(year_team)
This is a test ... show Tony some stuff.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
#### Test
#### Loading and Processing the Data
---
title: "Reproducible Research: Peer Assessment 1"
author: "Sam Edgemon"
date: "April 16, 2015"
output:
html_document:
keep_md: true
---
#### Test
#### Loading and Processing the Data
- set my working directory
- read in the zipped file, unzip it, and save it as "data"
- format date
```{r getdata}
setwd("~/GitHub/RepData_PeerAssessment1")
activity <- read.table(unz("activity.zip", "activity.csv"), header=T, quote="\"", sep=",")
activity$date <- as.Date(activity$date)
```
### What is mean total number of steps taken per day?
- Built dataset without missings
- Found daily steps
- Produced Mean
- Produced Median
- Produced Histogram
```{r}
activity.ignore.na <- na.omit(activity)
daily.steps <- rowsum(activity.ignore.na$steps, format(activity.ignore.na$date, '%Y-%m-%d'))
daily.steps <- data.frame(daily.steps)
names(daily.steps) <- ("steps")
mean(daily.steps$steps)
median(daily.steps$steps)
hist(daily.steps$steps,
main=" ",
breaks=10,
ylim=c(0, 30),
xlab="Total Number of Steps Taken Daily")
```
### What is the average daily activity pattern?
- load libraries
- create a variable called interval.mean.steps
- qplot
- identify interval with max steps
```{r}
library(plyr)
library(ggplot2)
interval.mean.steps <- ddply(activity.ignore.na,~interval, summarise, mean=mean(steps))
qplot(x=interval, y=mean, data = interval.mean.steps,  geom = "line",
xlab="5-Minute Interval",
ylab="Step Count",
main="Average Steps Taken - Averaged Across All Days"
)
# Maximum steps occurs on this interval:
interval.mean.steps[which.max(interval.mean.steps$mean), ]
```
### Imputing missing values
```{r}
# Number of Records with missing values
activity_NA <- sum(is.na(activity))
# Create a copy of the original data set - activity_i "activity impute"
activity_i <- activity
# Replace all NA steps values with the average number of steps for that interval
which <- which(is.na(activity$steps))
intervals <- activity[which, "interval"]
activity_i[which, "steps"] <- interval.mean.steps[interval.mean.steps == activity[which, "interval"], "mean"]
daily.steps <- rowsum(activity_i$steps, format(activity_i$date, '%Y-%m-%d'))
daily.steps <- data.frame(daily.steps)
names(daily.steps) <- ("steps")
hist(daily.steps$steps,
main=" ",
breaks=10,
ylim=c(0, 30),
xlab="Total Number of Steps Taken Daily (after imputation of missing values)")
```
### Are there differences in activity patterns between weekdays and weekends?
- build logical data frame of days
- create a new variable called weekday
-- assign logical values to weekday and weekend designations
- repeat an earlier step and get averages per interval
- create sub-plots by type
```{r}
days <- weekdays(as.Date(activity$date)) %in% c('Saturday','Sunday')
activity$weekday <- factor(days, labels = c("weekday", "weekend"))
steps_per_interval_weekday_avg <- aggregate(steps ~ interval + weekday, activity, FUN = mean)
g <- ggplot(steps_per_interval_weekday_avg, aes(x = interval, y = steps))
g <- g + facet_wrap(~ weekday, ncol = 1)
g <- g + geom_line()
g <- g + labs(x = "Interval")
g <- g + labs(y = "Mean Number of Steps")
g
```
### END Peer Assessment 1
#### Test2
summary(cars)
plot(cars)
